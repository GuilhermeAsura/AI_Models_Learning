{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zp7Mb4FcMDbA"
   },
   "source": [
    "00. PyTorch Fundamentals\n",
    "\n",
    "Resource notebook:https://www.learnpytorch.io/00_pytorch_fundamentals/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZCcvkTnAw6Y",
    "outputId": "7d8090d3-2c57-404a-d490-7d0b78ec795e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6k70cEk5FkR0"
   },
   "source": [
    "## Introdution to Tensors\n",
    "### Creating tensors\n",
    "\n",
    "PyTorch tensors are created using torch.Tensor() = https://pytorch.org/docs/stable/tensors.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LFA7CfBkPtuN",
    "outputId": "1458e9c5-8250-4da9-9e63-0d025bc5e220"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "czlGC1LTQHge",
    "outputId": "edbee73e-8e0f-43cb-805d-e6d15abf9e9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cxbMkpiERIgr",
    "outputId": "ac08d511-c4e3-4a78-e112-cba1460ba4f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tensor back as a python int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4405D1RiRQpc",
    "outputId": "f241ba4c-f98f-4648-b7f9-d89cb3308a08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47sAq_EcRfqQ",
    "outputId": "fd5149d5-2ff6-4598-fcd6-7186c0c2a673"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MQjBwznmRnPN",
    "outputId": "15564292-bd6e-40bd-9415-2c6dba6b1a88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "imXcjO5wRpY2",
    "outputId": "a01629ef-0e9e-4698-e9e8-36a25f07bbe4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix\n",
    "MATRIX = torch.tensor([[7,8],\n",
    "                       [9,10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UOuUdzLuR076",
    "outputId": "7bca8a98-5010-49fc-df6c-01827ec0fe9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ps4bjWH4SE9O",
    "outputId": "052e05f1-1267-4aca-b79d-0130d185ec49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fWiLwnuVSI07",
    "outputId": "ca4cacb9-a4a6-4187-82ed-2fb3dc24399d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nGUPpwxWSL5T",
    "outputId": "02275c9e-4997-4c7d-bbcb-3fbb14d6b834"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor\n",
    "TENSOR = torch.tensor([[[1,2,3],\n",
    "                        [3,6,9],\n",
    "                        [2,4,5]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QmWcB9yxSTBP",
    "outputId": "bdebdb6b-2ab5-4013-8631-a2f80108d57b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6qRmMYttSlQK",
    "outputId": "fbcc6460-2c01-4751-a750-86b1cedb1128"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PrjMMRIhSth0",
    "outputId": "d5dc7453-ee3f-43f0-fda0-86ef5fba8429"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [3, 6, 9],\n",
       "        [2, 4, 5]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JKCJwr1S9N6"
   },
   "source": [
    "### Random tensors\n",
    "\n",
    "Why random tensors?\n",
    "\n",
    "Are important because the way many NN learn is that they start tensors full of random numbers and then adjust those random numbers to better represent the data.\n",
    "\n",
    "> Adicionar aspas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CHSoRs-tVxSD",
    "outputId": "16020e6e-b39a-4bcd-e2e6-3bd00a1d1080"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2232, 0.3893, 0.2011, 0.5044],\n",
       "        [0.7138, 0.3690, 0.7674, 0.7166],\n",
       "        [0.5053, 0.4620, 0.1276, 0.2213]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of shape (3, 4)\n",
    "random_tensor = torch.rand(3, 4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xad5iBi1WLe_",
    "outputId": "04935809-0e2b-48b6-ba34-2f8cea705fdc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yAvUDqS9W7qy",
    "outputId": "eeb445d9-21d8-43a7-ef9f-4f4bd33dcf23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random tensor with similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3)) #Dimentions: height, width, color chanel (R, G, B)\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LOZEfMRSXFAe",
    "outputId": "656b4056-2b12-4e88-f90f-0227abc5c11b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4679, 0.9069, 0.5584],\n",
       "        [0.1763, 0.5148, 0.3111],\n",
       "        [0.2277, 0.7409, 0.0164]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(size=(3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOHjQHiBYA07"
   },
   "source": [
    "#### Zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ehNIF351YJg5",
    "outputId": "f110628a-dfcb-416f-87cf-0730d5bee601"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3,4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xOUef9RWYSEQ",
    "outputId": "6f18ace9-c9fd-41da-88a5-ae64f633b31d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3,4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7tjP7-Z7Yc2P",
    "outputId": "26a7207c-20e7-4ac5-c7fd-d4e99c4f4f8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BP_kSpXAYe2m",
    "outputId": "7d3a29f7-bc35-4f7b-e6e1-077e4a4704c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKG-fcMfYkLf"
   },
   "source": [
    "### Creating a range of tensor and tensor-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZNDG0ejZPeo",
    "outputId": "a17aac85-83ff-48ec-9ac3-53824698e216"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_ten = torch.arange(start=1, end=11, step=1)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVvgo7BnsvEf",
    "outputId": "05b04924-4596-44a1-9299-f6565dd2f36b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3452obX-tov9"
   },
   "source": [
    "### Tensors datatypes\n",
    "The most commons errors you'll run with PyTorch & DL:\n",
    "1. Tensors not right datatype\n",
    "2. Tensors not right shape\n",
    "3. Tensors not on right device\n",
    "\n",
    "Precision on Computing: https://en.wikipedia.org/wiki/Precision_(computer_science)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.4\n",
      "2.5.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)\n",
    "print(torch.__version__)\n",
    "# Should match your CUDA version (e.g., 12.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZPa6ukhutwrF",
    "outputId": "76d84fbd-4a02-4c81-8757-d78affc702b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None,\n",
    "                               device=\"cuda\",\n",
    "                               requires_grad=False)\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mroG2BTQvrWe",
    "outputId": "87992b01-75de-4d56-ff10-e405e7449156"
   },
   "outputs": [],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ccAZdetvvZB",
    "outputId": "11db6a69-7850-4680-8920-bfa83e022eae"
   },
   "outputs": [],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hFbTYpVwYSm"
   },
   "source": [
    "### Getting information from tensors\n",
    "\n",
    "    1. Tensors datatype ->  tensor.dtype\n",
    "    2. Tensors shape    ->  tensor.shape\n",
    "    3. Tensors device   ->  tensor.device\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YkubpDIeyQQx",
    "outputId": "0ac7c5cb-7acb-45ec-f059-22468185986e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7538, 0.3117, 0.2230, 0.9862],\n",
       "        [0.5249, 0.8605, 0.7130, 0.4210],\n",
       "        [0.5987, 0.1701, 0.6429, 0.5969]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor = torch.rand((3, 4), device = \"cuda\")\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUT0IxWkzEhV",
    "outputId": "45be717a-2cd8-4430-d003-97d6fa98c56c"
   },
   "outputs": [],
   "source": [
    "# Find out details about some tensor\n",
    "print(some_tensor)\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Device tensor is on: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ve4LVxh0zH5W"
   },
   "source": [
    "### Manipulating Tensors (tensor operations)\n",
    "\n",
    "Tensor operations include:\n",
    "\n",
    "- Addition\n",
    "- Subtraction\n",
    "- Multiplication (element-wise)\n",
    "- Division\n",
    "- Matrix Multiplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eDFXcBXWzw3p",
    "outputId": "d75272c9-1073-4802-a16c-689028773cf3"
   },
   "outputs": [],
   "source": [
    "# Create a tensor\n",
    "tensor = torch.tensor([1, 2, 3], device = \"cuda\", dtype = torch.float32)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x6WC2SZKz-eU",
    "outputId": "34dde736-3d4a-4bb3-a02e-e56b81e2db5b"
   },
   "outputs": [],
   "source": [
    "tensor + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JfyiPzs_0Ab7",
    "outputId": "80056d05-2f38-42a9-b7a3-c1201ca3341f"
   },
   "outputs": [],
   "source": [
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vQTBNo8R0DVi",
    "outputId": "04877e86-a3c4-4d90-9aa4-98f16bec3bea"
   },
   "outputs": [],
   "source": [
    "tensor -9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PVR6xFCJ0ZxK",
    "outputId": "f2d34a54-0088-4b88-ddc6-ef66578f367e"
   },
   "outputs": [],
   "source": [
    "# Try out PyTorch in-built functions\n",
    "torch.mul(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f32wvg5s0iPj",
    "outputId": "8175c836-d1de-493a-d0b7-9668654b0398"
   },
   "outputs": [],
   "source": [
    "torch.add(tensor, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ve4LVxh0zH5W"
   },
   "source": [
    "### Matrix manipulation\n",
    "\n",
    "Two main ways of performing multiplication on NN and DL:\n",
    "\n",
    "1. Element-wise multiplication\n",
    "2. Matrix multiplication (dot product)\n",
    "   \n",
    "info: https://www.mathsisfun.com/algebra/matrix-multiplying.html\n",
    "\n",
    "There are two rules that perfoming matrix multiplication needs to satisfy:\n",
    "1. The **inner dimensions** must match:\n",
    "- `(3, 2) @ (3, 2)` won't work\n",
    "- `(2, 3) @ (3, 2)` will work\n",
    "- `(3, 2) @ (2, 3)` will work\n",
    "\n",
    "The resulting matrix has the shape of the **outer dimensions**:\n",
    "- `(2, 3) @ (3, 2) -> (2, 2)`\n",
    "- `(3, 2) @ (2, 3) -> (3, 3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Element wise multiplication\n",
    "print ( tensor, \"*\", tensor)\n",
    "print(f\"Equals: {tensor*tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix multiplication\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul(torch.rand(3, 2), torch.rand(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ve4LVxh0zH5W"
   },
   "source": [
    "### One of the most common erros in DL: shape errors\n",
    "\n",
    "To fiz our tensor shape issues, we can manipulate the shape of one of our tensors using a **transpose**.\n",
    "\n",
    "A transpose switch the axes or dimensions of a given tensor -> `your_tensor.T`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m],\n\u001b[1;32m      6\u001b[0m                          [\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[1;32m      7\u001b[0m                          [\u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m12\u001b[39m]])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#torch.mm(tensor_A, tensor_B)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m torch\u001b[38;5;241m.\u001b[39mmatmul(tensor_A, tensor_B)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shapes for matrix multiplication\n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]])\n",
    "tensor_B = torch.tensor([[7, 8],\n",
    "                         [9, 10],\n",
    "                         [11, 12]])\n",
    "#torch.mm(tensor_A, tensor_B)\n",
    "torch.matmul(tensor_A, tensor_B) # it should return an error!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A.shape, tensor_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA Available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ve4LVxh0zH5W"
   },
   "source": [
    "### One of the most common erros in DL: shape errors\n",
    "\n",
    "To fiz our tensor shape issues, we can manipulate the shape of one of our tensors using a **transpose**.\n",
    "\n",
    "A transpose switch the axes or dimensions of a given tensor -> `your_tensor.T`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7,  8],\n",
       "         [ 9, 10],\n",
       "         [11, 12]]),\n",
       " torch.Size([3, 2]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B, tensor_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7,  9, 11],\n",
       "         [ 8, 10, 12]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.T, tensor_B.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 23,  29,  35],\n",
       "        [ 53,  67,  81],\n",
       "        [ 83, 105, 127]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor_A, tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 23,  53,  83],\n",
       "        [ 29,  67, 105],\n",
       "        [ 35,  81, 127]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor_B, tensor_A.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91]), torch.int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Finding the min, max, mean, sum, etc (tensor aggregation)\n",
    "x = torch.arange(1, 100, 10)\n",
    "x, x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor(1))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the min\n",
    "torch.min(x), x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(91), tensor(91))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the max\n",
    "torch.max(x), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(46.)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the mean - the torch.mean() function requires a tensor of float32 datatype to work\n",
    "torch.mean(x.type(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(460), tensor(460))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the sum\n",
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the positional min and max\n",
    "For this we can use:\n",
    "\n",
    "- `your_tensor.argmin()`\n",
    "\n",
    "- `your_tensor.argmax()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the position in tensor that has the minimun value with argmin() -> retuns index\n",
    "x.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the position in tensor that has the maximum value with argmax()\n",
    "x.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "\n",
    "- Reshaping: reshapes an input tensor to a defined shape;\n",
    "- View: Return a view of an input tensor of certain shape but keep the same memory as the original tensor;\n",
    "- Stacking: combine multiple tensors on top of each other (vstack) or side by side (hstack);\n",
    "- Squeeze: removes all `1` dimensions from a tensor;\n",
    "- Unsqueeze: add a `1` dimension to a target tensor;\n",
    "- Permute: Return a view of the input with dimensions permuted (swapped) in a certain way;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]), torch.Size([10]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.arange(1., 11.)\n",
    "y, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]),\n",
       " torch.Size([1, 10]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension\n",
    "y_reshaped = y.reshape(1, 10)\n",
    "y_reshaped, y_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.],\n",
       "         [ 2.],\n",
       "         [ 3.],\n",
       "         [ 4.],\n",
       "         [ 5.],\n",
       "         [ 6.],\n",
       "         [ 7.],\n",
       "         [ 8.],\n",
       "         [ 9.],\n",
       "         [10.]]),\n",
       " torch.Size([10, 1]))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reshaped2 = y.reshape(10, 1)\n",
    "y_reshaped2, y_reshaped2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.],\n",
       "         [ 3.,  4.],\n",
       "         [ 5.,  6.],\n",
       "         [ 7.,  8.],\n",
       "         [ 9., 10.]]),\n",
       " torch.Size([5, 2]))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reshaped3 = y.reshape(5, 2)\n",
    "y_reshaped3, y_reshaped3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
       "         [ 6.,  7.,  8.,  9., 10.]]),\n",
       " torch.Size([2, 5]))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reshaped4 = y.reshape(2, 5)\n",
    "y_reshaped4, y_reshaped4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]),\n",
       " torch.Size([1, 10]))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view\n",
    "z = y.view(1, 10)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]),\n",
       " tensor([ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing z changes y - because a view of a tensor shares the same memory as the original tensor\n",
    "z[:, 0] = 5\n",
    "z, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "        [ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "        [ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "        [ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "y_stacked = torch.stack([y, y, y, y], dim = 0)\n",
    "y_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove extra dimensions from the tensor\n",
    "y_squeezed = y_reshaped.squeeze()\n",
    "y_squeezed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_squeezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old tensor: tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
      "Old tensor: torch.Size([10])\n",
      "New tensor: tensor([[ 1.],\n",
      "        [ 2.],\n",
      "        [ 3.],\n",
      "        [ 4.],\n",
      "        [ 5.],\n",
      "        [ 6.],\n",
      "        [ 7.],\n",
      "        [ 8.],\n",
      "        [ 9.],\n",
      "        [10.]])\n",
      "New shape: torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "# torch.unsqueeze() - adds a single dim to a target tensor at especific dim\n",
    "y_unsqueezed = y_squeezed.unsqueeze(dim = 1)\n",
    "print(f\"Old tensor: {y_squeezed}\")\n",
    "print(f\"Old tensor: {y_squeezed.shape}\")\n",
    "print(f\"New tensor: {y_unsqueezed}\")\n",
    "print(f\"New shape: {y_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n"
     ]
    }
   ],
   "source": [
    "# torch.permute - rearranges the dim of a target in a specify order\n",
    "# simulate an image tensor \n",
    "x_original = torch.rand(size = (224, 224, 3)) # [height, width, color_channels]\n",
    "print(f\"Previous shape: {x_original.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Permute the original tensor to rearrange the axis (or dim) order\n",
    "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0 -> 1, 1 -> 2, 2-> 0\n",
    "print(f\"New shape: {x_permuted.shape}\") # [color_channels, height, width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New value for [0, 0, 0]: 666.0\n",
      "Checking if value correspond on permuted tensor: 666.0\n"
     ]
    }
   ],
   "source": [
    "x_original[0, 0, 0,] = 666\n",
    "print(f\"New value for [0, 0, 0]: {x_original[0, 0, 0]}\")\n",
    "print(f\"Checking if value correspond on permuted tensor: {x_permuted[0, 0, 0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing (selectinf data from tensors)\n",
    "\n",
    "Indexing with PyTorch is similar to indexing with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:  2.5.1\n",
      "CUDA Available: True\n",
      "PyTorch-Cuda version:  12.4\n",
      "Device name:  NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version: \",torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"PyTorch-Cuda version: \",torch.version.cuda)\n",
    "print(\"Device name: \", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing a tensor\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing on the middle bracket (dim = 1)\n",
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing on the most inner bracket (last dim)\n",
    "x[0][1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use \":\" to select \"all\" of a target dim, look:\n",
    "x[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 8, 9]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch tensors and NumPy\n",
    "\n",
    "NumPy is a popular scientific Python numerical computing library.\n",
    "And because of this, PyTorch has a functionality to interact with it.\n",
    "\n",
    "- Data in NumPy, want in PyTorch tensor -> `torch.from_numpy(ndarray)`\n",
    "- PyTorch tensor -> NumPy -> `torch.Tensor.numpy()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:  2.5.1\n",
      "CUDA Available: True\n",
      "PyTorch-Cuda version:  12.4\n",
      "Device name:  NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "print(\"PyTorch version: \",torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"PyTorch-Cuda version: \",torch.version.cuda)\n",
    "print(\"Device name: \", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy array to tensor\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array)\n",
    "# Warning when converting from numpy -> pytorch, pytorch reflecte numpy's default datatype \n",
    "# of float64 unless specified otherwise\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1.0, 8.0).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the value of array, what will this do to 'tensor'?\n",
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to NumPy array\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the tensors what happens to 'numpy_tensor'\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducbility (trying to take random out of random)\n",
    "In short how a neural network(NN) learns:\n",
    "\n",
    "`start with random numbers -> tensor operations -> update random numbers to try and make them better representations of the data -> again -> again -> again . . .`\n",
    "\n",
    "To reduce the randomness in NN and PyTorch comes the concept of a random seed.\n",
    "\n",
    "Essentially what the random seed does is \"flavour\" the randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:  2.5.1\n",
      "CUDA Available: True\n",
      "PyTorch-Cuda version:  12.4\n",
      "Device name:  NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version: \",torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"PyTorch-Cuda version: \",torch.version.cuda)\n",
    "print(\"Device name: \", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7544, 0.9823, 0.0577, 0.1624],\n",
      "        [0.0978, 0.3299, 0.3954, 0.1653],\n",
      "        [0.7697, 0.3431, 0.2021, 0.9147]])\n",
      "tensor([[0.4390, 0.8824, 0.9965, 0.3330],\n",
      "        [0.5133, 0.7817, 0.5744, 0.3686],\n",
      "        [0.1289, 0.7952, 0.6012, 0.6581]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "# Create random tensors:\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B)\n",
    "print(random_tensor_A == random_tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# Let's make some random but reproducible tensors\n",
    "# Set the random seed\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED) # generally only works for one block of code\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_C)\n",
    "print(random_tensor_D)\n",
    "print(random_tensor_C == random_tensor_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running tensors and PyTorch objects on the GPUs - and making faster computations.\n",
    "\n",
    "`GPU's` = faster computation on numbers, thanks to CUDA + NVIDIA Hardware + PyTorch working behind the scenes to make everything hunky dory (good)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Getting a GPU\n",
    "1. Easiest - Use `Google Colab` for a free `GPU` (options to upgrade as well);\n",
    "2. `Use your own GPU` -  takes a little bit of setup and requires the investment of purchasing a GPU, there's lots of options. . .\n",
    "3. Use `Cloud Computing` - GCP, AWS, Azure, these services allow you to rent computers on the cloud and access them;\n",
    "\n",
    "For 2, 3 PyTorch + GPU drivers (CUDA) takes a little bit of setting up. To do this, refer to PyTorch Doc's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar  5 17:37:47 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.120                Driver Version: 550.120        CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650        Off |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   48C    P8              1W /   50W |      69MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      4940      G   /usr/lib/xorg/Xorg                              4MiB |\n",
      "|    0   N/A  N/A     11843      C   ...erme-lazzarini/anaconda3/bin/python         60MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Check for GPU access with PyTorch \n",
    "For this use: `print(torch.cuda.is_available())`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:  2.5.1\n",
      "CUDA Available: True\n",
      "PyTorch-Cuda version:  12.4\n",
      "Device name:  NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version: \",torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available()) # checks for GPU access with PyTorch\n",
    "print(\"PyTorch-Cuda version: \",torch.version.cuda) \n",
    "print(\"Device name: \", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of devices\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Putting tensors (and models) on the GPU\n",
    "\n",
    "The reason we want our tensors/models on the GPU is because using a GPU results in faster computations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor (default on the CPU)\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Tensor not on GPU\n",
    "print(tensor, tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move tensor to GPU (if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Moving tensors back to the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[223], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# if tensor i son GPU, can't transform it to NumPy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tensor_on_gpu\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# if tensor i son GPU, can't transform it to NumPy\n",
    "tensor_on_gpu.numpy() # Expect an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3]), tensor([1, 2, 3], device='cuda:0'))"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To fix the GPU tensor with NumPy issue, we can first set it to the CPU\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu, tensor_on_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
